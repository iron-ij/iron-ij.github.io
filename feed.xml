<feed xmlns="http://www.w3.org/2005/Atom"> <id>https://iron-ij.github.io/</id><title>Iron's Blog</title><subtitle>A minimal, portfolio, sidebar, bootstrap Jekyll theme with responsive web design and focuses on text presentation.</subtitle> <updated>2021-12-13T18:04:47+09:00</updated> <author> <name>iron</name> <uri>https://iron-ij.github.io/</uri> </author><link rel="self" type="application/atom+xml" href="https://iron-ij.github.io/feed.xml"/><link rel="alternate" type="text/html" hreflang="en" href="https://iron-ij.github.io/"/> <generator uri="https://jekyllrb.com/" version="4.2.1">Jekyll</generator> <rights> © 2021 iron </rights> <icon>/assets/img/favicons/favicon.ico</icon> <logo>/assets/img/favicons/favicon-96x96.png</logo> <entry><title>머신러닝 디자인 패턴 정리 - 데이터 스케일링</title><link href="https://iron-ij.github.io/posts/machine-learning-design-patterns-2/" rel="alternate" type="text/html" title="머신러닝 디자인 패턴 정리 - 데이터 스케일링" /><published>2021-12-12T21:59:00+09:00</published> <updated>2021-12-12T21:59:00+09:00</updated> <id>https://iron-ij.github.io/posts/machine-learning-design-patterns-2/</id> <content src="https://iron-ij.github.io/posts/machine-learning-design-patterns-2/" /> <author> <name>iron</name> </author> <category term="머신러닝" /> <summary> 아마 시중에 있는 머신러닝/딥러닝 책을 구매해서 땋! 하고 펴보면 제일 먼저 Mnist(손글씨) 데이터셋이 주어지고 이를 통해 머신러닝 문제들을 해결하는 예제를 쉽게 접해볼 수 있다. 오늘 포스팅에서는 머신러닝 모델링을 진행하기 이전에 데이터 스케일링 과정은 왜 필요하며 어떤 것들이 있는지 살펴보고 책에 나와있는 내용 이외에 머신러닝 서비스를 염두할 때 고려해야할 점을 가볍게 정리해보고자 한다. #1 스케일링은 왜 필요할까? 경사하강법을 쓰는 경우에 더 빠른 수렴을 기대해볼 수 있다. loss가 크면 클수록 Computational cost가 커지고, 잘못된 가중치 업데이트로 이어질 수 있음 [-1, 1]로 스케일링을 하면 가장 높은 부동 소수점 정밀... </summary> </entry> <entry><title>AWS serverless로 nlp 모델 배포하기</title><link href="https://iron-ij.github.io/posts/serverless-nlp/" rel="alternate" type="text/html" title="AWS serverless로 nlp 모델 배포하기" /><published>2021-12-12T21:57:00+09:00</published> <updated>2021-12-13T18:04:19+09:00</updated> <id>https://iron-ij.github.io/posts/serverless-nlp/</id> <content src="https://iron-ij.github.io/posts/serverless-nlp/" /> <author> <name>iron</name> </author> <category term="nlp" /> <summary> AWS 배포시에 다음과 같은 장단이 있다 속도(구현 속도) : AWS(lambda) - 싸다, 구현하기 쉽다(파이썬 스크립트를 짜고) 그러나 아래 튜토리얼은 실제 서비스 환경과 거리가 있고 실제로는 훨씬 고려해야할 점이 많다. Aws로 이렇게 할 수 있구나! 정도만 참고하자 (아래 방식은 responce time도 긴 편이다ㅜㅜ) 1. serverless 설치 AWS에서 템플릿이용해서 serverless instance를 띄우는 것을 도와주는 라이브러리 AWS → 너무 명령어가 복잡(단계가 좀 많다) ⇒ serverless를 하기위해서 좀 편하게 템플릿을 잡아주는 것(라이브러리) # mac os 기준 npm install -g serverless 설치하게되면 AWS creden... </summary> </entry> <entry><title>Latent Semantic Analysis (LSA, 잠재의미 분석)</title><link href="https://iron-ij.github.io/posts/latent-semantic-analysis/" rel="alternate" type="text/html" title="Latent Semantic Analysis (LSA, 잠재의미 분석)" /><published>2021-12-05T21:57:00+09:00</published> <updated>2021-12-05T21:59:57+09:00</updated> <id>https://iron-ij.github.io/posts/latent-semantic-analysis/</id> <content src="https://iron-ij.github.io/posts/latent-semantic-analysis/" /> <author> <name>iron</name> </author> <category term="nlp" /> <summary> 잠재 의미 분석(LSA, LSI) BoW에 기반한 단어 - 문서 행렬 , TF-IDF는 기본적으로 단어의 빈도 수를 수치화하여 분석하는 방법론이었기 때문에 → 단어의 의미를 고려하지 못한다 라는 단점이 있었음 이를 보완하기 위한 대안으로 단어 - 문서 행렬의 잠재된(latent) 의미를 이끌어 내는 방법으로 잠재 의미 분석(LSA)을 활용함 (LSI 라고도 함) m x n (단어,문서) 행렬 → m x t, t x n 의 (단어, 토픽), (토픽, 문서) 행렬로 분해됨 How - to : 토픽모델링을 위해 고안된 아이디어라기 보기 보다는, SVD(개인적으로는, 활용관점에서 선대의 꽃이라고 생각)를 토픽 모델링이라는 분야에 활용한 사례라고 할 수 있음 1. 특이값 분해(Singula... </summary> </entry> <entry><title>Mac 초기환경 세팅하기</title><link href="https://iron-ij.github.io/posts/mac-default-setting/" rel="alternate" type="text/html" title="Mac 초기환경 세팅하기" /><published>2021-12-05T21:15:00+09:00</published> <updated>2021-12-05T21:15:00+09:00</updated> <id>https://iron-ij.github.io/posts/mac-default-setting/</id> <content src="https://iron-ij.github.io/posts/mac-default-setting/" /> <author> <name>iron</name> </author> <category term="etc" /> <summary> Mac 구매 또는 초기화 후에 개발환경을 세팅할 일이 간간히 있다. 2~3달에 한번정도는 하는 것 같은데, 그동안 매번 찾아서 하다가 나에게 맞는 세팅을 조금 맞춰놓고 싶어서 정리하게 되었다 1. Home brew 설치 $ /usr/bin/ruby -e "$(curl -fsSL [https://raw.githubusercontent.com/Homebrew/install/master/install](https://raw.githubusercontent.com/Homebrew/install/master/install))" $ echo 'export PATH="/usr/local/bin:$PATH"' &amp;gt;&amp;gt; ~/.bash_profile 2. 기본 프로그램 설치 주된 작업환경이 v... </summary> </entry> <entry><title>2.5 Linear independence</title><link href="https://iron-ij.github.io/posts/linear-independence/" rel="alternate" type="text/html" title="2.5 Linear independence" /><published>2021-11-28T21:50:00+09:00</published> <updated>2021-11-28T21:55:12+09:00</updated> <id>https://iron-ij.github.io/posts/linear-independence/</id> <content src="https://iron-ij.github.io/posts/linear-independence/" /> <author> <name>iron</name> </author> <category term="Math" /> <summary> 이번장에서 알고 가야할 정의 Linear Combination Linear Independent vector Linear dependent vector Definition 2.11 (Linear Combination) 벡터 공간 $V$와 유한한 벡터 $x_1,…,x_k \in V$ 이면, 모든 $v \in V$이 다음을 만족하면 벡터 $x_1,…,x_k \in V$와 $\lambda_1,…,\lambda_k \in R$의 선형결합(Linear combination)이라 정의한다 0-벡터는 항상 선형결합이다. \[v=\lambda_1x_1 + \cdot\cdot\cdot+\lambda_kx_k=\sum^k_{i=1}\lambda_... </summary> </entry> </feed>
